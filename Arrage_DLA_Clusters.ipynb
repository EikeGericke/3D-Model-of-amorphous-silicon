{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an 3D model of grains distributed in a volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is written to prepare a nanoscopic 3D model of hydrogenated amorphous silicon (a-Si:H). Besides this purpose the script can be used to randomly place grains defind by xyz coordinates in a pre defined volume. \n",
    "A volume is defined by the variables box_XY_Length and box_Z_Length. \n",
    "The main idea is to read batches of xyz positions from *.cvs files in a secondary directory (\"DLA_Cluster_ca100\" in this example). Here, these batches represen aggregates from diffusion limited aggregation (DLA) of grains defined by one xyz coordinat. The DLA were aggregated in around a xyz start point of 50,50,50. To move the coordination system of the DLA to the origin of the pre defined volume the variable start ist used. \n",
    "The a-Si:H model contains a second type of grains. This second type appears not to be arranged in DLA but to appear in pair, triplets and so on. They are placed randomly as well. \n",
    "Export files of the xyz positions of grains type one, type two and of the not occupied volume (called void here) are written. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a volume and distribute baches of xyz (lacated at data_location) coordinates in this volume randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of generated File 20200\n",
      "\n",
      "Name of exported file: DLAmodel_Cl200_XY140_Z20_Particles.csv\n",
      "\n",
      "Random distribution array construction =  0.0009970664978027344 seconds\n",
      "Loop over all files =  0.21592998504638672 seconds\n"
     ]
    }
   ],
   "source": [
    "#supposing the xyz batch is in a subdirectory of the project \n",
    "#give the name of the directory here.\n",
    "data_location = \"DLA_Cluster_ca100\" \n",
    "file_structure = \"*.csv\" #so later seach for the identifier .cvs\n",
    "outFileName = \"DLAmodel_Cl200_XY140_Z20_Particles\" # name the output file\n",
    "outFileTyp = \".csv\" # a text file will be saved anyway\n",
    "\n",
    "headerLen = 1 # number of header lines\n",
    "path = data_location + os.sep + file_structure\n",
    "outFile = outFileName + outFileTyp\n",
    "\n",
    "# Define the xy volume in which the DLA should be distributed\n",
    "box_XY_Length = 140 # XY Box Size\n",
    "box_Z_Length = 20 # Z Box Size\n",
    "limit = 250 # limit must be a higher number than files in the directory\n",
    "\n",
    "start = -50 # move axis center\n",
    "stopXY = start + box_XY_Length\n",
    "stopZ = start + box_Z_Length\n",
    "\n",
    "\n",
    "t1_start = time.time()\n",
    "\n",
    "# make random distrubution array\n",
    "randListX = [random.randint(start,stopXY) for iter in range(limit)]\n",
    "randListY = [random.randint(start,stopXY) for iter in range(limit)]\n",
    "randListZ = [random.randint(start,stopZ) for iter in range(limit)]\n",
    "arr0 = np.zeros((limit,),dtype=int)\n",
    "arrX = np.array(randListX,dtype=int)\n",
    "arrY = np.array(randListY,dtype=int)\n",
    "arrZ = np.array(randListZ,dtype=int)\n",
    "arrVec = np.stack((arr0,arrX,arrY,arrZ)).transpose()\n",
    "vector = iter(np.array(arrVec))\n",
    "\n",
    "t2_stop = time.time()\n",
    "#print(arrVec)\n",
    "\n",
    "# grep all files from the folder and distribute them in a volme\n",
    "merg = np.array([[0,0,0,0],[0,0,0,0]]) # will be deleted later\n",
    "\n",
    "t3_start = time.time()\n",
    "\n",
    "for filepath in glob.iglob(path):\n",
    "    #print(filepath)\n",
    "    data = np.loadtxt(filepath, delimiter=',', dtype = int, skiprows=headerLen)\n",
    "    data = data + next(vector)\n",
    "    merg = np.append(merg,data,axis = 0)\n",
    "merg = np.delete(merg,[0,1],0)\n",
    "\n",
    "t4_stop = time.time()\n",
    "\n",
    "partDF = pd.DataFrame(merg, columns=[\"Counter\",\"X\",\"Y\",\"Z\"])\n",
    "partDF = partDF.drop(columns=[\"Counter\"])\n",
    "partDF = partDF.drop_duplicates(keep=\"first\")\n",
    "\n",
    "print( )\n",
    "print(\"Length of generated File\", len(merg))\n",
    "print()\n",
    "#------Save to file-------\n",
    "partDF.to_csv(outFile,index=False)\n",
    "#-------------------------\n",
    "\n",
    "print(\"Name of exported file:\", outFile)\n",
    "print()\n",
    "print(\"Random distribution array construction = \", t2_stop - t1_start , \"seconds\")\n",
    "print(\"Loop over all files = \", t4_stop - t3_start , \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Randomly position clusters of the second type of grains (voids).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the number of grains of the first type\n",
    "nDOD = len(partDF)\n",
    "#the second type of grains appear 0.031 times as much as the first type\n",
    "nVac = int(round(nDOD*0.031,0))\n",
    "\n",
    "vacX_list = list()\n",
    "vacY_list = list()\n",
    "vacZ_list = list()\n",
    "\n",
    "nVIter = iter(list(range(nVac)))\n",
    "\n",
    "#position a number of grains of second type (nVac) in small clusters of 1, 2, or 3 grains\n",
    "#clSize defines the number of grains in a cluster\n",
    "for element in nVIter:\n",
    "    clSize = random.randint(1,3)\n",
    "    clSizeList = list(range(clSize-1))\n",
    "    xPos = random.randint(1,box_XY_Length)\n",
    "    yPos = random.randint(1,box_XY_Length)\n",
    "    zPos = random.randint(1,box_Z_Length)\n",
    "    \n",
    "    vacX_list.append(xPos)\n",
    "    vacY_list.append(yPos)\n",
    "    vacZ_list.append(zPos)\n",
    "    \n",
    "    #print(\"Cluster size:\", clSize)\n",
    "    #print(element,\"xyz:\" , xPos, yPos, zPos)\n",
    "    for element in clSizeList:\n",
    "        position = next(nVIter)\n",
    "        xPos = random.randint(xPos-1,xPos+1)\n",
    "        yPos = random.randint(yPos-1,yPos+1)\n",
    "        zPos = random.randint(zPos-1,zPos+1)\n",
    "        \n",
    "        vacX_list.append(xPos)\n",
    "        vacY_list.append(yPos)\n",
    "        vacZ_list.append(zPos)\n",
    "        #print(position,\"xyz:\" , xPos, yPos, zPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of grains type two: 598\n"
     ]
    }
   ],
   "source": [
    "vacDF = pd.DataFrame({\"X\": vacX_list,\n",
    "                      \"Y\": vacY_list,\n",
    "                      \"Z\": vacZ_list})\n",
    "vacDF = vacDF.drop_duplicates(keep=\"first\")\n",
    "print(\"Number of grains type two:\", len(vacDF))\n",
    "\n",
    "outFileName = \"DLAmodel_Cl200_XY140_Z20_Vacancies\" # name the generated file\n",
    "outFileTyp = \".csv\" # a text file will be saved anyway\n",
    "outFile = outFileName + outFileTyp\n",
    "vacDF.to_csv(outFile,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export a file that contains all xyz positions not occupied by grains of type one or two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a file of the not occupied space\n",
    "\n",
    "listX = list(range(-5,box_XY_Length+5+1))\n",
    "listY = list(range(-5,box_XY_Length+5+1))\n",
    "listZ = list(range(-5,box_Z_Length+5+1))\n",
    "#find all combinations of listsXYZ\n",
    "volumeArray = np.array(np.meshgrid(listX, listY, listZ)).T.reshape(-1,3)\n",
    "#make pandas DataFrame from this\n",
    "volumeDF = pd.DataFrame(volumeArray, columns=[\"X\",\"Y\",\"Z\"])\n",
    "volumeDF = volumeDF.drop_duplicates(keep=\"first\")\n",
    "\n",
    "voidDF = pd.concat([volumeDF,partDF,vacDF]).drop_duplicates(keep=False)\n",
    "\n",
    "outFileName_volume = \"DLAmodel_Cl200_XY140_Z20_Volume\" # name the generated file\n",
    "outFileTyp = \".csv\" # a text file will be saved anyway\n",
    "outFile = outFileName_volume + outFileTyp\n",
    "\n",
    "voidDF.to_csv(outFile,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xyz positions on volume: 706831\n",
      "Number of grains type one: 19687\n",
      "Number of grains type two: 598\n",
      "Number of not occupied positions: 686640\n"
     ]
    }
   ],
   "source": [
    "print(\"xyz positions on volume:\",len(volumeDF))\n",
    "print(\"Number of grains type one:\",len(partDF))\n",
    "print(\"Number of grains type two:\",len(vacDF))\n",
    "print(\"Number of not occupied positions:\",len(voidDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
